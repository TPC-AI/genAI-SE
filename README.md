# Large-scale Generative AI for Science and Engineering

In this graduate-level course, we will investigate large generative AI models for scientific and engineering problems: machine learning models that are specifically trained on scientific and engineering data. They can generate outputs, such as hypotheses, designs, or simulations, based on patterns learned from those data. In more detail:

* **Generative**: The model can produce new content based on patterns and structures learned during training. In the science and engineering context, it could generate predictions about untested physical phenomena, propose new design configurations for a mechanical system, or simulate the performance of a new material, to name a few examples.
* **AI model**: It uses machine learning algorithms that the model uses to learn from data and generate outputs. These algorithms are designed to identify patterns and make predictions or decisions without being explicitly programmed to perform a specific task.
* **Large**: In this context, "large" refers to the number of parameters in the model. The parameters are elements of the model that are learned from the data during training. A large model has many parameters, allowing it to learn more complex patterns, but also requiring more computational resources to train and use.
* **For Science and Engineering**: Training data might include scientific articles, textbooks, lab reports, CAD models, numerical simulation data, experimental data, or any other type of data that is relevant to these fields. Training the model on this type of data equips it to generate outputs that are relevant to scientific and engineering tasks.
  
<!--Such models may be useful in accelerating research, generating novel hypotheses, optimizing designs, and much more.-->

## Topics

We will study theoretical underpinnings of such models, their training paradigms, and applications. 
We will explore how these models can generate new data that are statistically similar to their training data, including text, images, and potentially more abstract representations, and how this capacity can be harnessed for scientific discovery and engineering solutions.
Key topics include:
*	Fundamentals of machine learning and deep learning
*	Overview of large-scale generative models
*	Deep dive into generative models like GPTs, GANs, VAEs
*	Training and fine-tuning strategies for generative models
*	Use cases of generative AI in various scientific fields like physics, chemistry, and biology, and in engineering disciplines such as materials science and electrical engineering
*	Practical sessions on implementation of these models with popular deep learning frameworks
*	Exploration of the limitations and ethical considerations of using AI in science and engineering
  
By the end of the course, students will have an understanding of how to implement and use generative AI models, how to apply them to problems in science and engineering, and how to navigate the ethical considerations that arise with the use of AI in these fields.


## Applications


## Potential topics with relevant readings




### Memorization and copyright protection

* [On Provable Copyright Protection for Generative Models](https://arxiv.org/pdf/2302.10870.pdf), Nikhil Vyas et al., 2023.
* [Emergent and Predictable Memorization in Large Language Models](https://arxiv.org/pdf/2304.11158.pdf), Stella Biderman et al., 2023.
